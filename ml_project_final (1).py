# -*- coding: utf-8 -*-
"""ML_project_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IMDm9u-QsHPgaBESYOyyJPurgvD0xb2_
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install vaderSentiment

"""# Preprocessing"""

import pandas as pd
import numpy as np
import math
import random
import matplotlib.pyplot as plt
# import utils

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.ensemble import AdaBoostClassifier
from sklearn import preprocessing

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import log_loss
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

import warnings
warnings.filterwarnings("ignore", category=UserWarning)

#  Loading the database
url = "/content/drive/MyDrive/zomato.csv"
df = pd.read_csv(url)
print(df.head)

df=df.drop(['dish_liked'],axis=1)
df=df.drop(['url', 'address', 'phone', 'menu_item'], axis=1)
df=df.dropna()
df=df.drop_duplicates()

df.rate=df.rate.replace({'-':'0/5','NEW':'0/5'})
df.rate=df.rate.astype(str)
df.rate=df.rate.apply(lambda row: row.replace('/5',''))
df.rate=df.rate.astype(float)

df['approx_cost(for two people)']=df['approx_cost(for two people)'].astype(str)
df['approx_cost(for two people)']=df['approx_cost(for two people)'].apply(lambda row: row.replace(',',''))
df['approx_cost(for two people)']=df['approx_cost(for two people)'].astype(float)

df['rest_type'] = df['rest_type'].astype('str')
df['rest_type'] = df['rest_type'].apply(lambda string: string.split(','))
df['rest_type'] = df['rest_type'].apply(lambda lst: sorted([string.strip() for string in lst]))
df['rest_type'] = df['rest_type'].apply(lambda lst: ', '.join(lst))

# correct cuisines column (change order)
df['cuisines'] = df['cuisines'].astype('str')
df['cuisines'] = df['cuisines'].apply(lambda string: string.split(','))
df['cuisines'] = df['cuisines'].apply(lambda lst: sorted([string.strip() for string in lst]))
df['cuisines'] = df['cuisines'].apply(lambda lst: ', '.join(lst))

df["reviews_list"] = df["reviews_list"].apply(eval)
reviews_count=[len(r) for r in df['reviews_list']]
df["reviews_list"]=reviews_count

lst = [0]*len(df.index)
df["label"] = lst
for i in df.index:
  if df["rate"][i] < 3.5:
    df["label"][i] = 0
  else:
    df["label"][i] = 1

def encode_column(df, column):
  le = preprocessing.LabelEncoder()
  le.fit(df[column].unique())
  df[column] = le.transform(df[column])
  mean = df[column].mean()
  std_dev = df[column].std()
  df[column] = df[column].apply(lambda x: (x - mean) / std_dev)
  return df

# Dropping columns
df = df.drop(["rate", "name"], axis = 1)

# Encoding columns

df = encode_column(df, "online_order")
df = encode_column(df, "book_table")
df = encode_column(df, "location")
df = encode_column(df, "rest_type")
df = encode_column(df, "cuisines")
df = encode_column(df, "listed_in(type)")
df = encode_column(df, "listed_in(city)")

"""# Running models without sentiment ananlysis"""

clf_lr = LogisticRegression(random_state = 0, max_iter = 500)
clf_dt_entropy = DecisionTreeClassifier(criterion="entropy", max_depth=15, random_state = 0)
clf_dt_gini = DecisionTreeClassifier(criterion="gini", max_depth=15, random_state = 0)
clf_rf = RandomForestClassifier(max_depth=3, random_state=0)
clf_svc = SVC(random_state = 0)
clf_adaboost = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth = 3), n_estimators=100, random_state=0)
clf_mlp_relu = MLPClassifier(random_state=0, hidden_layer_sizes = (256, 128), max_iter=1000, early_stopping = True, activation = "relu", solver = "adam")
clf_mlp_tanh = MLPClassifier(random_state=0, hidden_layer_sizes = (256, 128), max_iter=1000, early_stopping = True, activation = "tanh", solver = "adam")
clf_mlp_sigmoid = MLPClassifier(random_state=0, hidden_layer_sizes = (256, 128), max_iter=1000, early_stopping = True, activation = "logistic", solver = "adam")
clf_mlp_linear = MLPClassifier(random_state=0, hidden_layer_sizes = (256, 128), max_iter=1000, early_stopping = True, activation = "identity", solver = "adam")

def get_k_folds(df, k):
  size = len(df.index) // k
  df_shuffled = df.sample(frac = 1)
  folds = []
  start = 0
  for i in range(k - 1):
    folds.append(df_shuffled.iloc[start:start + size,:])
    start += size
  folds.append(df_shuffled.iloc[start:, :])
  return folds

def train_k_fold(clf, df, k):

  print("===========================================================================")
  print("Model", clf)
  folds = get_k_folds(df, k)
  train_accuracies = []
  test_accuracies = []
  f1_scores = []
  for i in range(k):
    temp = folds.copy()
    test_df = folds[i]
    temp.pop(i)
    train_df = pd.concat(temp)
    train_labels = train_df["label"]
    test_labels = test_df["label"]
    train_df = train_df.drop(["label"], axis = 1)
    test_df = test_df.drop(["label"], axis = 1)
    clf.fit(train_df, train_labels)
    train_predictions = clf.predict(train_df)
    test_predictions = clf.predict(test_df)
    train_loss = log_loss(train_labels, train_predictions)
    test_loss = log_loss(test_labels, test_predictions)
    train_accuracy = accuracy_score(train_labels, train_predictions)
    test_accuracy = accuracy_score(test_labels, test_predictions)
    train_accuracies.append(train_accuracy)
    test_accuracies.append(test_accuracy)
    macro_f1 = f1_score(test_labels, test_predictions, average="macro")
    f1_scores.append(macro_f1)
    print("===========================================================================")
    print("Training loss for fold {0}: {1}".format(i + 1, train_loss))
    print("Testing loss for fold {0}: {1}".format(i + 1, test_loss))
    print("Training accuracy for fold {0}: {1}".format(i + 1, train_accuracy))
    print("Testing accuracy for fold {0}: {1}".format(i + 1, test_accuracy))
    print("Macro F1-Score for fold {0}: {1}".format(i + 1, macro_f1))
    print("===========================================================================")
  return sum(train_accuracies) / k, sum(test_accuracies) / k, sum(f1_scores) / k

lr_train_accuracy, lr_accuracy, lr_f1 = train_k_fold(clf_lr, df, 4)

dt_entropy_train_accuracy, dt_entropy_accuracy, dt_entropy_f1 = train_k_fold(clf_dt_entropy, df, 4)

dt_gini_train_accuracy, dt_gini_accuracy, dt_gini_f1 = train_k_fold(clf_dt_gini, df, 4)

rf_train_accuracy, rf_accuracy, rf_f1 = train_k_fold(clf_rf, df, 4)

adaboost_train_accuracy, adaboost_accuracy, adaboost_f1 = train_k_fold(clf_adaboost, df, 4)

svc_train_accuracy, svc_accuracy, svc_f1 = train_k_fold(clf_svc, df, 4)

mlp_train_accuracy_relu, mlp_accuracy_relu, mlp_f1_relu = train_k_fold(clf_mlp_relu, df, 4)

mlp_train_accuracy_tanh, mlp_accuracy_tanh, mlp_f1_tanh = train_k_fold(clf_mlp_tanh, df, 4)

mlp_train_accuracy_sigmoid, mlp_accuracy_sigmoid, mlp_f1_sigmoid = train_k_fold(clf_mlp_sigmoid, df, 4)

mlp_train_accuracy_linear, mlp_accuracy_linear, mlp_f1_linear = train_k_fold(clf_mlp_linear, df, 4)

print("============================================================")
print("Combined results")
print("============================================================")
print("Training accuracy for Logisitic regression:", lr_train_accuracy)
print("Testing accuracy for Logisitic regression:", lr_accuracy)
print("Macro_f1 score for Logisitic regression: ", lr_f1)
print("============================================================")
print("Training accuracy for Decision tree (entropy):", dt_entropy_train_accuracy)
print("Testing accuracy for Decision tree (entropy):", dt_entropy_accuracy)
print("Macro_f1 score for Decision tree (entropy): ", dt_entropy_f1)
print("============================================================")
print("Training accuracy for Decision tree (gini):", dt_gini_train_accuracy)
print("Testing accuracy for Decision tree (gini):", dt_gini_accuracy)
print("Macro_f1 score for Decision tree (gini): ", dt_gini_f1)
print("============================================================")
print("Training accuracy for Random Forest:", rf_train_accuracy)
print("Testing accuracy for Random Forest:", rf_accuracy)
print("Macro_f1 score for Random forest: ", rf_f1)
print("============================================================")
print("Training accuracy for AdaBoost classifier:", adaboost_train_accuracy)
print("Testing accuracy for AdaBoost classifier:", adaboost_accuracy)
print("Macro_f1 score for AdaBoost classifier: ", adaboost_f1)
print("============================================================")
print("Training accuracy for Support vector classifier:", svc_train_accuracy)
print("Testing accuracy for Support vector classifier:", svc_accuracy)
print("Macro_f1 score for Support vector classifier: ", svc_f1)
print("============================================================")
print("Training Accuracy for MLP classifier (relu):", mlp_train_accuracy_relu)
print("Testing accuracy for MLP classifier (relu):", mlp_accuracy_relu)
print("Macro_f1 score for MLP classifier (relu): ", mlp_f1_relu)
print("============================================================")
print("Training Accuracy for MLP classifier (tanh):", mlp_train_accuracy_tanh)
print("Testing accuracy for MLP classifier (tanh):", mlp_accuracy_tanh)
print("Macro_f1 score for MLP classifier (tanh): ", mlp_f1_tanh)
print("============================================================")
print("Training Accuracy for MLP classifier (sigmoid):", mlp_train_accuracy_sigmoid)
print("Testing accuracy for MLP classifier (sigmoid):", mlp_accuracy_sigmoid)
print("Macro_f1 score for MLP classifier (sigmoid): ", mlp_f1_sigmoid)
print("============================================================")
print("Training Accuracy for MLP classifier (linear):", mlp_train_accuracy_linear)
print("Testing accuracy for MLP classifier (linear):", mlp_accuracy_linear)
print("Macro_f1 score for MLP classifier (linear): ", mlp_f1_linear)
print("============================================================")

"""# Doing sentiment analysis"""

url = "/content/drive/MyDrive/zomato.csv"
df_new = pd.read_csv(url)

df_new=df_new.drop(['dish_liked'],axis=1)
df_new=df_new.drop(['url', 'address', 'phone', 'menu_item', 'name'], axis=1)
df_new=df_new.dropna()
df_new=df_new.drop_duplicates()

df_new.rate=df_new.rate.replace({'-':'0/5','NEW':'0/5'})
df_new.rate=df_new.rate.astype(str)
df_new.rate=df_new.rate.apply(lambda row: row.replace('/5',''))
df_new.rate=df_new.rate.astype(float)

df_new['approx_cost(for two people)']=df_new['approx_cost(for two people)'].astype(str)
df_new['approx_cost(for two people)']=df_new['approx_cost(for two people)'].apply(lambda row: row.replace(',',''))
df_new['approx_cost(for two people)']=df_new['approx_cost(for two people)'].astype(float)

df_new['rest_type'] = df_new['rest_type'].astype('str')
df_new['rest_type'] = df_new['rest_type'].apply(lambda string: string.split(','))
df_new['rest_type'] = df_new['rest_type'].apply(lambda lst: sorted([string.strip() for string in lst]))
df_new['rest_type'] = df_new['rest_type'].apply(lambda lst: ', '.join(lst))

# correct cuisines column (change order)
df_new['cuisines'] = df_new['cuisines'].astype('str')
df_new['cuisines'] = df_new['cuisines'].apply(lambda string: string.split(','))
df_new['cuisines'] = df_new['cuisines'].apply(lambda lst: sorted([string.strip() for string in lst]))
df_new['cuisines'] = df_new['cuisines'].apply(lambda lst: ', '.join(lst))


df_new = encode_column(df_new, "online_order")
df_new = encode_column(df_new, "book_table")
df_new = encode_column(df_new, "location")
df_new = encode_column(df_new, "rest_type")
df_new = encode_column(df_new, "cuisines")
df_new = encode_column(df_new, "listed_in(type)")
df_new = encode_column(df_new, "listed_in(city)")


lst = [0]*len(df_new.index)
df_new["label"] = lst
for i in df_new.index:
  if df_new["rate"][i] < 3.5:
    df_new["label"][i] = 0
  else:
    df_new["label"][i] = 1

df_new=df_new.drop(['rate'], axis=1)

df_new["reviews_list"] = df_new["reviews_list"].apply(eval)

# Giving sentiment scores to reviews using vader
sentiment_analyzer = SentimentIntensityAnalyzer()
df_new["review_sentiment"] = [0.0]*len(df_new.index)

for i in df_new.index:
  pol_sum = 0
  count = 0
  for j in df_new["reviews_list"][i]:
    sentence = j[1][9:]
    pol_sum += sentiment_analyzer.polarity_scores(sentence)['compound']
    count += 1
  if count != 0:
    df_new["review_sentiment"][i] = pol_sum / count

df_new = df_new.drop(["reviews_list"], axis = 1)

lr_train_accuracy_sent, lr_accuracy_sent, lr_f1_sent = train_k_fold(clf_lr, df_new, 4)

dt_entropy_train_accuracy_sent, dt_entropy_accuracy_sent, dt_entropy_f1_sent = train_k_fold(clf_dt_entropy, df_new, 4)

dt_gini_train_accuracy_sent, dt_gini_accuracy_sent, dt_gini_f1_sent = train_k_fold(clf_dt_gini, df_new, 4)

rf_train_accuracy_sent, rf_accuracy_sent, rf_f1_sent = train_k_fold(clf_rf, df_new, 4)

adaboost_train_accuracy_sent, adaboost_accuracy_sent, adaboost_f1_sent = train_k_fold(clf_adaboost, df_new, 4)

svc_train_accuracy_sent, svc_accuracy_sent, svc_f1_sent = train_k_fold(clf_svc, df_new, 4)

mlp_train_accuracy_relu_sent, mlp_accuracy_relu_sent, mlp_f1_relu_sent = train_k_fold(clf_mlp_relu, df_new, 4)

mlp_train_accuracy_sigmoid_sent, mlp_accuracy_sigmoid_sent, mlp_f1_sigmoid_sent = train_k_fold(clf_mlp_sigmoid, df_new, 4)

mlp_train_accuracy_tanh_sent, mlp_accuracy_tanh_sent, mlp_f1_tanh_sent = train_k_fold(clf_mlp_tanh, df_new, 4)

mlp_train_accuracy_linear_sent, mlp_accuracy_linear_sent, mlp_f1_linear_sent = train_k_fold(clf_mlp_linear, df_new, 4)

print("============================================================")
print("Combined results")
print("============================================================")
print("Training accuracy for Logisitic regression:", lr_train_accuracy_sent)
print("Testing accuracy for Logisitic regression:", lr_accuracy_sent)
print("Macro f1 score for Logisitic regression: ", lr_f1_sent)
print("============================================================")
print("Training accuracy for Decision tree (entropy):", dt_entropy_train_accuracy_sent)
print("Testing accuracy for Decision tree (entropy):", dt_entropy_accuracy_sent)
print("Macro f1 score for Decision tree (entropy): ", dt_entropy_f1_sent)
print("============================================================")
print("Training accuracy for Decision tree (gini):", dt_gini_train_accuracy_sent)
print("Testing accuracy for Decision tree (gini):", dt_gini_accuracy_sent)
print("Macro f1 score for Decision tree (gini): ", dt_gini_f1_sent)
print("============================================================")
print("Training accuracy for Random Forest:", rf_train_accuracy_sent)
print("Testing accuracy for Random Forest:", rf_accuracy_sent)
print("Macro f1 score for Random forest: ", rf_f1_sent)
print("============================================================")
print("Training accuracy for AdaBoost classifier:", adaboost_train_accuracy_sent)
print("Testing accuracy for AdaBoost classifier:", adaboost_accuracy_sent)
print("Macro f1 score for AdaBoost classifier: ", adaboost_f1_sent)
print("============================================================")
print("Training accuracy for Support vector classifier:", svc_train_accuracy_sent)
print("Testing accuracy for Support vector classifier:", svc_accuracy_sent)
print("Macro f1 score for Support vector classifier: ", svc_f1_sent)
print("============================================================")
print("Training Accuracy for MLP classifier (relu):", mlp_train_accuracy_relu_sent)
print("Testing accuracy for MLP classifier (relu):", mlp_accuracy_relu_sent)
print("Macro f1 score for MLP classifier (relu): ", mlp_f1_relu_sent)
print("============================================================")
print("Training Accuracy for MLP classifier (tanh):", mlp_train_accuracy_tanh_sent)
print("Testing accuracy for MLP classifier (tanh):", mlp_accuracy_tanh_sent)
print("Macro f1 score for MLP classifier (tanh): ", mlp_f1_tanh_sent)
print("============================================================")
print("Training Accuracy for MLP classifier (sigmoid):", mlp_train_accuracy_sigmoid_sent)
print("Testing accuracy for MLP classifier (sigmoid):", mlp_accuracy_sigmoid_sent)
print("Macro f1 score for MLP classifier (sigmoid): ", mlp_f1_sigmoid_sent)
print("============================================================")
print("Training Accuracy for MLP classifier (linear):", mlp_train_accuracy_linear_sent)
print("Testing accuracy for MLP classifier (linear):", mlp_accuracy_linear_sent)
print("Macro f1 score for MLP classifier (linear): ", mlp_f1_linear_sent)
print("============================================================")